<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="FMB: A Functional Manipulation Benchmark for Generalizable Robotic Learning">
  <meta name="keywords" content="FMB, Robotic">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FMB: A Functional Manipulation Benchmark for Generalizable Robotic Learning</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-QELSVHQK1T"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
  
    gtag('config', 'G-QELSVHQK1T');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.png">
  <link rel="stylesheet" href="./main.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="https://kit.fontawesome.com/9e7d48e44c.js" crossorigin="anonymous"></script>

</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WXK4VLVD" height="0" width="0"
      style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>

    <a class="navbar-item" href=./index.html>
      Home
    </a>
    <a class="navbar-item" href=./dataset/index.html>
      Dataset
    </a>

    <a class="navbar-item" href=./files/index.html>
      Benchmark
    </a>
    <!-- <a class="navbar-item" href=./setup/index.html>
      Workspace Setup
    </a>
    <a class="navbar-item" href=./procedure/index.html>
      Evaluation Procedure
    </a> -->
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-widescreen">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">FMB: A Functional Manipulation Benchmark for Generalizable Robotic
              Learning</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://people.eecs.berkeley.edu/~jianlanluo/">Jianlan Luo<sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://charlesxu0124.github.io/">Charles Xu</a><sup>*</sup>,</span>
              <span class="author-block">
                <a href="https://fangchenliu.github.io/">Fangchen Liu</a>,</span>
              <span class="author-block">
                <a href="https://liam-tan.github.io/">Liam Tan</a>,</span>
              <span class="author-block">
                <a href="https://zipeng-lin.github.io/">Zipeng Lin</a>,</span>
              <span class="author-block">
                <a href="https://jeffreywu13579.github.io/">Jeffrey Wu</a>,</span>
              <span class="author-block">
                <a href="http://people.eecs.berkeley.edu/~pabbeel/">Pieter Abbeel</a> and</span>
              <span class="author-block">
                <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>
              </span>
            </div>

            <div class="is-size-9 publication-authors">
              <span class="author-block"><sup>*</sup> Equal Contribution</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2401.08553" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class='far fa-file-alt'></i>
                   </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://youtu.be/ynSj8le6r0k" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <!-- <span class="link-block">
                  <a href="https://github.com/manipulationdataset/ManipulationDataset"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span> -->
                <span class="link-block">
                  <a
                    class="button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code (Coming Soon)</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="dataset/index.html" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <img src="icons/database.png" style="width: 65%;">
                    </span>
                    <span>Dataset</span>
                  </a>
                </span>
                <!-- Benchmark Link. -->
                <span class="link-block">
                  <a href="files/index.html" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <img src="icons/robot.png" style="width: 90%;">
                    </span>
                    <span>Benchmark</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>

    <div class="container is-widescreen">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <!-- <h2 class="title is-3">A Functional Manipulation Benchmark for Generalizable Robotic Learning</h2> -->
          <img src="./static/images/FMB Objects.jpg" alt="Overview">
          <div class="content has-text-justified">
            Our benchmark for studying robotic learning for functional manipulation consists of a variety of easily
            reproducible 3D printed objects, each one requiring a sequence of grasping, reorientation, and assembly
            behaviors. Generalization can be evaluated on test objects and varied positions, as well as more complex
            multi-stage assembly tasks. We also provide an imitation learning system that provides a basic set of
            policies for each skill, allowing researchers to use our tasks as a toolkit for studying any portion of the
            pipeline.
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Paper video. -->
      <!-- <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/gt3wxt-rXfo?si=8C6EGg9HyBaY6ltp"
              title="YouTube video player" frameborder="0"
              allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
              allowfullscreen></iframe>
          </div>
        </div>
      </div> -->
      <!--/ Paper video. -->
    </div>
  </section>

  <!-- TODO: embed google survey -->

  <section class="section">
    <div class="container is-widescreen">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Dataset Overview</h2>
          <img src="./static/images/pie chart 2.png" alt="Overview">
          <div class="content has-text-justified">
            Our dataset consists of objects in diverse appearance and geometry. It requires multi-stage
            and multi-modal fine motor skills to successfully assemble the pegs onto a unfixed board in
            a randomized scene. We collected a total of 22,550 trajectories across two different tasks on
            a Franka Panda arm. We record the trajectories from 2 global views and 2 wrist views. Each view
            contains both RGB and depth map.
            <br>
            <br>
            Visit the <a href="dataset/index.html">dataset page</a> for more detail and links to download the dataset.
          </div>
        </div>
      </div>

      <div class="container is-widescreen">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h3 class="title is-4">Single-Object Multi-Stage Manipulation Task</h3>
            <div class="video-container" style="text-align: center;">
              <video src="./static/videos/peg.mp4" autoplay playsinline loop muted style="width: 60%; margin: auto; display: block;">
                Your browser does not support the video tag.
              </video>
              </div>
            <img src="./static/images/Single peg film strip.jpg" alt="Overview">
            <div class="content has-text-justified">
              The Single-Object Multi-Stage Manipulation Task consists of 54 different assembly objects and 3 assembly
              boards of various shapes, sizes, and colors. The robot has to grasp the object, perform a series of
              reorientation actions with an environment fixture, then insert into the board. The time horizon for this
              task ranges from 20 to 40 seconds. To make the task managable, we break down each
              end-to-end trajectory into seperate primitives such as grasp, place on fixture, regrasp, rotate, move to
              board, and insert. Examples of each trajectories can be visualized below.
            </div>
          </div>
        </div>

        <div class="content-container">
          <div class="video-container" id="peg-sampler">
            <div class="video-header">
              <h3>View a Random Trajectory</h3>
              <div id="sample-button-peg">
                <img src="icons/replay.svg" />
                <div>Sample</div>
              </div>
            </div>
            <div class="traj-sampler">
            <div class="video-grid lang">
              <div class="method">Side 1 View</div>
              <div class="method">Side 2 View</div>
              <div class="method">Wrist 1 View</div>
              <div class="method">Wrist 2 View</div>
              <div class="video"><video id="side_1_image_peg" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="side_2_image_peg" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="wrist_1_image_peg" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="wrist_2_image_peg" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="side_1_image_peg_depth" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="side_2_image_peg_depth" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="wrist_1_image_peg_depth" preload="auto" playsinline loop autoplay muted></video></div>
              <div class="video"><video id="wrist_2_image_peg_depth" preload="auto" playsinline loop autoplay muted></video></div>
            </div>
            <div class="outside-video-grid" id="annotation_peg">loading...</div>
          </div></div>
        </div>
      </div>


      <div class="container is-widescreen">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <h3 class="title is-4">Multi-Object Multi-Stage Manipulation Task</h3>
            <div class="video-container" style="text-align: center;">
              <video src="./static/videos/board.mp4" autoplay loop playsinline muted style="width: 60%; margin: auto; display: block;">
                Your browser does not support the video tag.
              </video>
              </div>
            <img src="./static/images/Board filmstrip.jpg" alt="Overview">
            <div class="content has-text-justified">
              The Multi-Object Multi-Stage Manipulation Task consists of 3 sets of assembly object. Each set contains 4
              interlocking objects that need to be assembled together sequentially using the same primitives as the
              previous task. The time horizon for this task is even longer, and can easily exceed 100 seconds to fully
              assemble one board. Examples of each trajectories can be visualized below.
            </div>
          </div>
        </div>
        <div class="container is-widescreen">
          <div class="content-container">
            <div class="video-container" id="board-sampler">
              <div class="video-header">
                <h3>View a Random Trajectory</h3>
                <div id="sample-button-board">
                  <img src="icons/replay.svg" />
                  <div>Sample</div>
                </div>
              </div>
              <div class="traj-sampler">
              <div class="video-grid lang">
                <div class="method">Side 1 View</div>
                <div class="method">Side 2 View</div>
                <div class="method">Wrist 1 View</div>
                <div class="method">Wrist 2 View</div>
                <div class="video"><video id="side_1_image_board" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="side_2_image_board" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="wrist_1_image_board" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="wrist_2_image_board" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="side_1_image_board_depth" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="side_2_image_board_depth" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="wrist_1_image_board_depth" preload="auto" playsinline loop autoplay muted></video></div>
                <div class="video"><video id="wrist_2_image_board_depth" preload="auto" playsinline loop autoplay muted></video></div>
              </div>
            <div class="outside-video-grid" id="annotation_board">loading...</div>
          </div></div>
          </div>
        </div>
      </div>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h3 class="title is-4">Reproducing the Benchmark</h3>
          <!-- <img src="./static/images/Board filmstrip.jpg" alt="Overview"> -->
          <div class="content has-text-justified">
            All the objects in our benchmark are designed to be 3D printable. We provide the CAD files for all the
            objects and links to material needed in the <a href="files/index.html#materials-cad-files">Material and
              CAD Files</a> section.
            <br>
            <br>
            A detailed description on how to setup the workspace can be found in the <a
              href="files/index.html#workspace">Workspace Setup</a> section.

            <br>
            <br>
            We also provide a detailed description of the evaluation procedure in the <a
              href="files/index.html#eval">Evaluation Procedure</a> section.
          </div>
        </div>
      </div>
  </section>



  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              If you have any questions about this project, please contact us at functionalmanipulationdataset@gmail.com
            </p>
            <p>
              All data is provided under the <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons
                Attribution 4.0 International License </a>.
            </p>
            <p>
              This website was built off of <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a> source
              code and
              the trajectory visualizer was adapted from <a href="https://rail-berkeley.github.io/bridgedata/">Bridge
                Data V2</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <script>
    // replay button animation
    new Image().src = 'icons/replay.svg' // preload

    const playButtons = document.querySelectorAll('.play-button');
    playButtons.forEach((button) => {
      button.addEventListener('click', () => {
        button.parentElement.parentElement.querySelectorAll('video').forEach((video) => {
          try {
            video.fastSeek(0);
          } catch (error) {
            video.currentTime = 0;
          }
          video.play();
        });
        const img = button.querySelector('img');
        img.src = 'icons/replay.svg';

        const text = button.querySelector('div');
        text.innerText = 'Replay';

        button.classList.remove('replay');
        void button.offsetWidth;
        button.classList.add('replay');
      });
    });
    // View Random Trajectory Widget
    var trajLinksPeg;
    fetch("peg.csv")
      .then(response => response.text())
      .then(text => trajLinksPeg = text.split(/\r\n|\n/).filter(line => line.trim().length > 0 && line.split(",").length === 9))
      .then(sample_peg);



    const prefixPeg = "peg_example_trajectory_mp4_depth/";
    const side1ImagePeg = document.querySelector("#side_1_image_peg");
    const side2ImagePeg = document.querySelector("#side_2_image_peg");
    const wrist1ImagePeg = document.querySelector("#wrist_1_image_peg");
    const wrist2ImagePeg = document.querySelector("#wrist_2_image_peg");
    const side1ImagePegDepth = document.querySelector("#side_1_image_peg_depth");
    const side2ImagePegDepth = document.querySelector("#side_2_image_peg_depth");
    const wrist1ImagePegDepth = document.querySelector("#wrist_1_image_peg_depth");
    const wrist2ImagePegDepth = document.querySelector("#wrist_2_image_peg_depth");
    const annotationPeg = document.querySelector("#annotation_peg");
    function sample_peg() {
      if (typeof trajLinksPeg === 'undefined') return;

      const index = Math.floor(Math.random() * trajLinksPeg.length);
      const links = trajLinksPeg[index].split(",");

      side1ImagePeg.src = prefixPeg + links[0];
      side1ImagePeg.load();
      side1ImagePeg.play();

      side2ImagePeg.src = prefixPeg + links[1];
      side2ImagePeg.load();
      side2ImagePeg.play();

      wrist1ImagePeg.src = prefixPeg + links[2];
      wrist1ImagePeg.load();
      wrist1ImagePeg.play();

      wrist2ImagePeg.src = prefixPeg + links[3];
      wrist2ImagePeg.load();
      wrist2ImagePeg.play();

      side1ImagePegDepth.src = prefixPeg + links[4];
      side1ImagePegDepth.load();
      side1ImagePegDepth.play();

      side2ImagePegDepth.src = prefixPeg + links[5];
      side2ImagePegDepth.load();
      side2ImagePegDepth.play();

      wrist1ImagePegDepth.src = prefixPeg + links[6];
      wrist1ImagePegDepth.load();
      wrist1ImagePegDepth.play();

      wrist2ImagePegDepth.src = prefixPeg + links[7];
      wrist2ImagePegDepth.load();
      wrist2ImagePegDepth.play();

      annotationPeg.innerText = links[8];
    }

    const sampleButtonPeg = document.querySelector('#sample-button-peg');
    sampleButtonPeg.addEventListener('click', () => {
      if (wrist2ImagePeg.readyState === 0) return; // Check if video is ready

      sample_peg();

      sampleButtonPeg.classList.remove('replay');
      void sampleButtonPeg.offsetWidth;
      sampleButtonPeg.classList.add('replay');
    });

    // -------------------------------------------------------------Board

    var trajLinksBoard;
    fetch("board.csv")
      .then(response => response.text())
      .then(text => trajLinksBoard = text.split(/\r\n|\n/).filter(line => line.trim().length > 0 && line.split(",").length === 9))
      .then(sample_board);



    const prefixBoard = "board_example_trajectory_mp4_depth/";
    const side1ImageBoard = document.querySelector("#side_1_image_board");
    const side2ImageBoard = document.querySelector("#side_2_image_board");
    const wrist1ImageBoard = document.querySelector("#wrist_1_image_board");
    const wrist2ImageBoard = document.querySelector("#wrist_2_image_board");
    const side1ImageBoardDepth = document.querySelector("#side_1_image_board_depth");
    const side2ImageBoardDepth = document.querySelector("#side_2_image_board_depth");
    const wrist1ImageBoardDepth = document.querySelector("#wrist_1_image_board_depth");
    const wrist2ImageBoardDepth = document.querySelector("#wrist_2_image_board_depth");
    const annotationBoard = document.querySelector("#annotation_board");
    function sample_board() {
      if (typeof trajLinksBoard === 'undefined') return;

      const index = Math.floor(Math.random() * trajLinksBoard.length);
      const links = trajLinksBoard[index].split(",");

      side1ImageBoard.src = prefixBoard + links[0];
      // console.log('side1ImageBoard src:', side1ImageBoard.src);
      side1ImageBoard.load();
      side1ImageBoard.play();

      side2ImageBoard.src = prefixBoard + links[1];
      side2ImageBoard.load();
      side2ImageBoard.play();

      wrist1ImageBoard.src = prefixBoard + links[2];
      wrist1ImageBoard.load();
      wrist1ImageBoard.play();

      wrist2ImageBoard.src = prefixBoard + links[3];
      wrist2ImageBoard.load();
      wrist2ImageBoard.play();

      side1ImageBoardDepth.src = prefixBoard + links[4];
      side1ImageBoardDepth.load();
      side1ImageBoardDepth.play();

      side2ImageBoardDepth.src = prefixBoard + links[5];
      side2ImageBoardDepth.load();
      side2ImageBoardDepth.play();

      wrist1ImageBoardDepth.src = prefixBoard + links[6];
      wrist1ImageBoardDepth.load();
      wrist1ImageBoardDepth.play();

      wrist2ImageBoardDepth.src = prefixBoard + links[7];
      wrist2ImageBoardDepth.load();
      wrist2ImageBoardDepth.play();

      annotationBoard.innerText = links[8];
    }

    const sampleButtonBoard = document.querySelector('#sample-button-board');
    sampleButtonBoard.addEventListener('click', () => {
      if (wrist2ImageBoard.readyState === 0) return; // Check if video is ready

      sample_board();

      sampleButtonBoard.classList.remove('replay');
      void sampleButtonBoard.offsetWidth;
      sampleButtonBoard.classList.add('replay');
    });

  </script>

</body>

</html>
